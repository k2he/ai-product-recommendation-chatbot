# Product Recommendation Chatbot

A production-ready AI-powered chatbot that recommends BestBuy Canada products based on user needs, using RAG (Retrieval-Augmented Generation) with LangChain and Pinecone.

---

## ğŸš€ Features

- **Smart Intent Detection** â€” LLM classifies every message as search, email, or purchase before any search is performed
- **Intelligent Product Search** â€” Pinecone vector similarity search over BestBuy Canada catalogue data
- **Self-Querying Retriever (SQR)** â€” Single LangChain component that decomposes a natural language query into a semantic search string **and** a structured Pinecone metadata filter in one LLM call â€” no manual JSON parsing or separate rephrase step
- **Metadata Filtering** â€” Filters on `categoryName`, `salePrice`, `customerRating`, and `isOnSale` are built automatically by SQR and applied natively in Pinecone
- **User Management** â€” MongoDB-based user profiles (name, email) used in responses and actions
- **Email & Purchase Actions** â€” Triggered by UI buttons or free-text (e.g. "send it to my email")
- **Purchase CTA in every response** â€” After showing products, the assistant always asks if the user wants to email or purchase
- **Optimistic UI** â€” "Alright [Name], let me help you with that. Give me a second! â³" shown instantly while the API responds
- **Category Registry** â€” All unique `categoryName` values are extracted at load time and saved for filter prompting
- **LangSmith Tracing** â€” Full observability of every chain execution
- **Modern UI** â€” Responsive React + Tailwind CSS interface

---

## ğŸ“‹ Technology Stack

### Backend
| Technology | Role |
|---|---|
| FastAPI (Python 3.11+) | REST API framework |
| LangChain | AI workflow: intent_chain, SelfQueryingRetriever, response_chain |
| Ollama (`gpt-oss:20b` + `nomic-embed-text`) | Local LLM inference & embeddings |
| Pinecone | Vector database with metadata filtering |
| MongoDB | User profile storage |
| UV | Python package manager |
| LangSmith | Tracing & debugging |

### Frontend
| Technology | Role |
|---|---|
| React 18 | UI framework |
| Vite | Build tool |
| Tailwind CSS | Styling |
| Axios | HTTP client |
| Lucide React | Icons |

### Infrastructure
- Docker & Docker Compose
- Nginx reverse proxy

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  React UI                   â”‚
â”‚  - Optimistic "Give me a second!" message  â”‚
â”‚  - Product cards with Email/Purchase btns  â”‚
â”‚  - Tracks lastProductIds for intent        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ POST /api/v1/chat
                     â”‚ { query, last_product_ids }
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI Backend                â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚       LangChain Workflow            â”‚   â”‚
â”‚  â”‚                                     â”‚   â”‚
â”‚  â”‚  Step 0: intent_chain (LLM)         â”‚   â”‚
â”‚  â”‚    â†’ "search" / "email" / "purchase"â”‚   â”‚
â”‚  â”‚         â”‚                           â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚
â”‚  â”‚    â”‚ email/purchase  â”‚  search      â”‚   â”‚
â”‚  â”‚    â–¼                 â–¼              â”‚   â”‚
â”‚  â”‚  execute_action  SelfQueryingRetriever   â”‚
â”‚  â”‚  (skip search)   (Steps 1+3 merged) â”‚   â”‚
â”‚  â”‚                  â”œâ”€ LLM decomposes  â”‚   â”‚
â”‚  â”‚                  â”‚  query â†’ string  â”‚   â”‚
â”‚  â”‚                  â”‚  + filter dict   â”‚   â”‚
â”‚  â”‚                  â””â”€ Pinecone search â”‚   â”‚
â”‚  â”‚                     with filter     â”‚   â”‚
â”‚  â”‚                      â”‚             â”‚   â”‚
â”‚  â”‚                  MongoDB (user)     â”‚   â”‚
â”‚  â”‚                      â”‚             â”‚   â”‚
â”‚  â”‚                      â”‚             â”‚   â”‚
â”‚  â”‚                  response_chain     â”‚   â”‚
â”‚  â”‚                  + CTA (LLM)        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚            â”‚
        â–¼            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Pinecone â”‚  â”‚MongoDB â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Workflow Details

### Chat Flow (Step by Step)

```
User types: "show me laptops under $1500 that are on sale"
                â”‚
                â–¼
Step 0 â”€â”€ intent_chain (LLM)
          Output: { "intent": "search", "product_hint": null }
                â”‚
                â–¼ (intent = "search")
Step 1 â”€â”€ MongoDB â†’ fetch user (name, email)
                â”‚
                â–¼
Steps  â”€â”€ SelfQueryingRetriever (single LLM call â€” replaces old rephrase + filter steps)
2 + 3     â”Œâ”€ LLM decomposes query into:
          â”‚    semantic string: "laptop sale discount under 1500"
          â”‚    filter: {
          â”‚      "categoryName": { "$eq": "Laptops" },
          â”‚      "salePrice":    { "$lte": 1500 },
          â”‚      "isOnSale":     { "$eq": true }
          â”‚    }
          â””â”€ Pinecone similarity search with filter applied natively
                â”‚
                â–¼
Step 4 â”€â”€ response_chain (LLM)
          Generates friendly response + mandatory CTA:
          "Would you like me to send these to your email, or purchase one?"
                â”‚
                â–¼
        Return to frontend
        { message, products[], source }
```

### Intent-Based Action Flow (New)

When a user types something like *"email me the MacBook"* or *"I'll take it"*:

```
User message + last_product_ids (from frontend state)
                â”‚
                â–¼
Step 0 â”€â”€ intent_chain (LLM)
          Output: { "intent": "email", "product_hint": "MacBook" }
                â”‚
                â–¼ (intent â‰  "search", last_product_ids present)
          Match product_hint against last shown products
          â†’ resolve target product SKU
                â”‚
                â–¼
          execute_action("email" | "purchase", product_id, user_id)
          â†’ email_service.send_product_email() OR
          â†’ purchase simulation (order ID returned)
                â”‚
                â–¼
          Return confirmation message (no products in response)
          { message: "Done! Sent to kai@...", source: "action" }
```

### Button Action Flow (Existing)

Clicking Email / Purchase buttons on a product card sends directly to `POST /api/v1/actions` â€” bypassing chat and intent detection entirely.

---

## ğŸ“¦ Data Format

Products are loaded from BestBuy Canada JSON files with the structure:

```json
{
  "products": [
    {
      "sku": "18470962",
      "name": "Apple AirPods 4 ...",
      "shortDescription": "Rebuilt for exceptional comfort...",
      "customerRating": 4.0,
      "productUrl": "/en-ca/product/.../18470962",
      "regularPrice": 179.99,
      "salePrice": 149.99,
      "saleEndDate": 1771574399000,
      "categoryName": "Wireless Earbuds & Earphones"
    }
  ]
}
```

The loader transforms each product to:
- Prefix `productUrl` with `https://www.bestbuy.ca`
- Derive `isOnSale = saleEndDate !== null`
- Store `text = name + " " + shortDescription` as the Pinecone embedding text
- Store all fields as Pinecone metadata for filtering

### Category Registry

After loading, all unique `categoryName` values are saved to `backend/data/categories.json`:

```json
{
  "categories": ["Apple MacBook Air", "Laptops", "Wireless Earbuds & Earphones"],
  "total": 3
}
```

This file is read at startup by `ChatbotService._load_categories()` and injected into the `SelfQueryingRetriever`'s `AttributeInfo` description for `categoryName`, so the LLM inside SQR knows exactly which values are valid to filter on. Re-run `load_products.py` whenever the product catalogue changes to keep this in sync.

---

## ğŸ“‹ API Endpoints

| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/api/v1/health` | Health check |
| `POST` | `/api/v1/chat` | Chat (search + intent detection) |
| `POST` | `/api/v1/actions` | Execute email/purchase via button |
| `POST` | `/api/v1/users` | Create user |
| `GET` | `/api/v1/users/{user_id}` | Get user |

### `POST /api/v1/chat` â€” Request Body

```json
{
  "query": "show me headphones under $200",
  "conversation_id": "conv_abc123",
  "last_product_ids": ["18470962", "18470963"]
}
```

- `last_product_ids`: SKUs of products shown in the previous assistant message. The frontend tracks and sends these automatically to enable free-text email/purchase intents.

---

## ğŸš¦ Prerequisites

- Docker & Docker Compose
- Ollama running locally with `gpt-oss:20b` and `nomic-embed-text` models
- Pinecone API key (free tier available at pinecone.io)
- SMTP credentials (optional â€” enables real email sending)

---

## ğŸ“¦ Installation

### 1. Clone the Repository

```bash
git clone <repository-url>
cd product-recommendation-chatbot
```

### 2. Configure Environment

```bash
cd backend
cp .env.example .env
# Edit .env â€” add your PINECONE_API_KEY, SMTP credentials
```

### 3. Add Product Data

Place your BestBuy JSON files in `backend/data/products/`:

```
backend/data/products/
â”œâ”€â”€ laptops.json
â””â”€â”€ headphones.json
```

Each file must use the `{ "products": [...] }` wrapper format.

### 4. Start Services

```bash
cd ..
docker-compose up -d
```

### 5. Pull Ollama Models

```bash
docker exec -it product_chatbot_ollama ollama pull gpt-oss:20b
docker exec -it product_chatbot_ollama ollama pull nomic-embed-text
```

### 6. Initialize Database & Load Products

```bash
# Create sample users in MongoDB
docker exec -it product_chatbot_backend python scripts/init_db.py

# Load products into Pinecone + save categories.json
docker exec -it product_chatbot_backend python scripts/load_products.py
```

`load_products.py` will:
1. Parse all JSON files in `data/products/` (supporting the `{ "products": [] }` format)
2. Transform and validate each product
3. Save unique `categoryName` values to `data/categories.json`
4. Upsert all products into Pinecone with full metadata

### 7. Access the Application

| Service | URL |
|---|---|
| Frontend Chat UI | http://localhost:3000 |
| Backend API | http://localhost:8000 |
| API Docs (Swagger) | http://localhost:8000/docs |
| LangSmith Traces | https://smith.langchain.com |

---

## ğŸ¯ Example Interactions

**Product search with filters:**
> "Show me laptops under $1500 that are highly rated"
â†’ LLM extracts: `salePrice â‰¤ 1500`, `customerRating â‰¥ 4.0`
â†’ Pinecone filtered search â†’ product cards + CTA

**Free-text email intent:**
> "Can you send the MacBook to my email?"
â†’ LLM detects `intent: email`, matches "MacBook" in last shown products
â†’ Email sent â†’ confirmation message (no new search)

**Free-text purchase intent:**
> "I'll take the Sony ones"
â†’ LLM detects `intent: purchase`, matches "Sony" in last shown products
â†’ Order simulated â†’ order ID returned

**On-sale filter:**
> "Any headphones on sale right now?"
â†’ LLM extracts: `isOnSale: true`, `categoryName: { $in: ["Wireless Earbuds & Earphones"] }`
â†’ Filtered Pinecone search

---

## ğŸ—‚ï¸ Project Structure

```
product-recommendation-chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ product.py          # ProductBase (BestBuy fields), ProductDocument
â”‚   â”‚   â”‚   â”œâ”€â”€ request.py          # ChatRequest (+ last_product_ids), ActionRequest
â”‚   â”‚   â”‚   â””â”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”‚   â”œâ”€â”€ mongodb.py
â”‚   â”‚   â”‚   â””â”€â”€ pinecone_db.py      # build_sqr() factory, add_products, get_product_by_id
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ chatbot_service.py  # intent_chain, SQR (_run_sqr), response_chain
â”‚   â”‚   â”‚   â”œâ”€â”€ data_loader.py      # BestBuy format support + category extraction
â”‚   â”‚   â”‚   â”œâ”€â”€ email_service.py
â”‚   â”‚   â”‚   â””â”€â”€ user_service.py
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ routes.py           # /chat passes last_product_ids to service
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ products/               # BestBuy JSON files (laptops.json, headphones.json)
â”‚   â”‚   â””â”€â”€ categories.json         # Auto-generated by load_products.py
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ init_db.py
â”‚       â””â”€â”€ load_products.py        # Loads products + saves categories.json
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ ChatInterface.jsx   # Passes userName to useChat
â”‚       â”‚   â”œâ”€â”€ MessageList.jsx
â”‚       â”‚   â”œâ”€â”€ InputBox.jsx
â”‚       â”‚   â””â”€â”€ ProductCard.jsx
â”‚       â”œâ”€â”€ hooks/
â”‚       â”‚   â””â”€â”€ useChat.js          # Optimistic message, lastProductIds tracking
â”‚       â””â”€â”€ services/
â”‚           â””â”€â”€ api.js              # sendMessage includes last_product_ids
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸ” LangSmith Tracing

Every chain execution is automatically traced. View at https://smith.langchain.com.

**Trace structure per request:**
```
User query: "email me the MacBook"
â”œâ”€ intent_chain            â†’ { intent: "email", product_hint: "MacBook" }  (0.8s)
â”‚
â””â”€ execute_action          â†’ email sent to kai@example.com                  (0.3s)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
User query: "laptops on sale under $2000"
â”œâ”€ intent_chain            â†’ { intent: "search" }                           (0.7s)
â”œâ”€ MongoDB                 â†’ user: Kai He                                    (0.1s)
â”œâ”€ SelfQueryingRetriever   â†’ LLM decomposes query + filter                  (1.1s)
â”‚  â”œâ”€ semantic string:       "laptop sale discount"
â”‚  â”œâ”€ filter:                { categoryName: "Laptops", salePrice: â‰¤2000,
â”‚  â”‚                           isOnSale: true }
â”‚  â””â”€ Pinecone search:       4 products returned                            (0.6s)
â””â”€ response_chain          â†’ friendly message + CTA                         (2.0s)
```

---

## ğŸ› ï¸ Troubleshooting

**No products returned despite correct query:**
- Check `categories.json` exists in `backend/data/` â€” if missing, re-run `load_products.py`
- Verify Pinecone index has vectors: check `/api/v1/health` and Pinecone dashboard
- Check LangSmith trace for the SQR step â€” look at what filter it generated; it may be too restrictive

**SQR generating wrong or overly strict filters:**
- Inspect the SQR trace in LangSmith â€” the `query_constructor` sub-chain shows the exact filter generated
- If a category is not in `categories.json`, SQR won't use it â€” re-run `load_products.py` to regenerate
- If filters are too aggressive, consider removing the `categoryName` filter from the query and letting semantic search handle it

**Intent always resolves to "search":**
- This is the safe default â€” confirm `last_product_ids` is being sent from the frontend
- Check LangSmith trace for the `intent_chain` output

**Email not sending:**
- Verify SMTP credentials in `.env`
- The service logs the error but returns a graceful failure message

---

## ğŸ“ Environment Variables

```env
# Pinecone
PINECONE_API_KEY=your_key
PINECONE_INDEX_NAME=product-recommendations
PINECONE_DIMENSION=768
PINECONE_NAMESPACE=products

# Ollama
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=gpt-oss:20b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# MongoDB
MONGODB_URL=mongodb://mongodb:27017
MONGODB_DB_NAME=chatbot


# LangSmith (optional)
LANGSMITH_API_KEY=your_key
LANGSMITH_PROJECT=product-chatbot
LANGSMITH_TRACING=true

# Search (SQR uses TOP_K; threshold filtering is handled by Pinecone natively via SQR)
SEARCH_TOP_K=5

# SMTP (optional)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your@email.com
SMTP_PASSWORD=your_password
SMTP_FROM=your@email.com
```
